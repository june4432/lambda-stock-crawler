"""
Playwrightë¥¼ ì‚¬ìš©í•œ í•œì†”í™€ë”©ìŠ¤ íˆ¬ìë¶„ì„ ë°ì´í„° í¬ë¡¤ëŸ¬
ë” ë¹ ë¥´ê³  ì•ˆì •ì ì¸ í¬ë¡¤ë§ì„ ìœ„í•´ Playwright ì‚¬ìš©
"""

import asyncio
import pandas as pd
from playwright.async_api import async_playwright
import json
from datetime import datetime, timezone, timedelta
import os
import re
from s3_utils import upload_file_to_s3, generate_s3_key
from dotenv import load_dotenv
import sys

# Windowsì—ì„œ Unicode ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if os.name == 'nt':
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# .env íŒŒì¼ ë¡œë“œ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ)
if os.path.exists('.env'):
    load_dotenv()

class PlaywrightStockCrawler:
    def __init__(self, headless=None, wait_timeout=None):
        """
        Playwright í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            headless (bool): ë¸Œë¼ìš°ì €ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í• ì§€ ì—¬ë¶€ (í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
            wait_timeout (int): ìš”ì†Œ ëŒ€ê¸° ì‹œê°„ (ë°€ë¦¬ì´ˆ) (í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
        """
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ê°’ ì½ê¸°
        self.headless = headless if headless is not None else os.environ.get('HEADLESS', 'true').lower() == 'true'
        self.wait_timeout = wait_timeout or int(os.environ.get('WAIT_TIMEOUT', '10000'))
        self.browser = None
        self.page = None
        self.start_time = None
        self.end_time = None
    
    def start_timer(self):
        """í¬ë¡¤ë§ ì‹œì‘ ì‹œê°„ ê¸°ë¡"""
        self.start_time = datetime.now()
        timestamp = self.start_time.strftime("%Y-%m-%d %H:%M:%S")
        print(f"ğŸ• í¬ë¡¤ë§ ì‹œì‘: {timestamp}")
        
    def end_timer(self):
        """í¬ë¡¤ë§ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡ ë° ì†Œìš”ì‹œê°„ ê³„ì‚°"""
        self.end_time = datetime.now()
        timestamp = self.end_time.strftime("%Y-%m-%d %H:%M:%S")
        print(f"ğŸ• í¬ë¡¤ë§ ì¢…ë£Œ: {timestamp}")
        
        if self.start_time:
            duration = self.end_time - self.start_time
            total_seconds = int(duration.total_seconds())
            hours = total_seconds // 3600
            minutes = (total_seconds % 3600) // 60
            seconds = total_seconds % 60
            
            if hours > 0:
                duration_str = f"{hours}ì‹œê°„ {minutes}ë¶„ {seconds}ì´ˆ"
            elif minutes > 0:
                duration_str = f"{minutes}ë¶„ {seconds}ì´ˆ"
            else:
                duration_str = f"{seconds}ì´ˆ"
            
            print(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {duration_str}")
            return duration
        return None
        
    async def setup_browser(self):
        """ë¸Œë¼ìš°ì € ì„¤ì • ë° ì´ˆê¸°í™”"""
        try:
            self.playwright = await async_playwright().start()
            
            # Chromium ë¸Œë¼ìš°ì € ì‹¤í–‰ (Lambda ìµœì í™”)
            browser_args = [
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-blink-features=AutomationControlled',
                '--disable-web-security',
                '--disable-features=VizDisplayCompositor',
                '--disable-background-timer-throttling',
                '--disable-backgrounding-occluded-windows',
                '--disable-renderer-backgrounding',
                '--disable-ipc-flooding-protection',
                '--disable-background-networking'
            ]
            
            # Lambda í™˜ê²½ì—ì„œ ì¶”ê°€ ìµœì í™”
            if os.environ.get('AWS_LAMBDA_FUNCTION_NAME'):
                browser_args.extend([
                    '--single-process',
                    '--disable-gpu',
                    '--disable-software-rasterizer',
                    '--memory-pressure-off'
                ])
                
            self.browser = await self.playwright.chromium.launch(
                headless=self.headless,
                args=browser_args
            )
            
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„± (User-Agent í¬í•¨)
            self.context = await self.browser.new_context(
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                          '(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            
            # ìƒˆ í˜ì´ì§€ ìƒì„±
            self.page = await self.context.new_page()
            
            # ë·°í¬íŠ¸ ì„¤ì •
            await self.page.set_viewport_size({"width": 1920, "height": 1080})
            
            print("âœ… Playwright ë¸Œë¼ìš°ì €ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            print(f"âŒ ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise
            
    async def navigate_to_page(self, url):
        """í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            print(f"ğŸ“„ í˜ì´ì§€ ì´ë™ ì¤‘: {url}")
            
            # í˜ì´ì§€ ë¡œë“œ
            await self.page.goto(url, wait_until='domcontentloaded', timeout=30000)
            
            # ì¶”ê°€ ë¡œë”© ëŒ€ê¸°
            await self.page.wait_for_timeout(3000)
            
            print("âœ… í˜ì´ì§€ ë¡œë”© ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ ì´ë™ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            raise
            
    async def select_finGubun(self, finGubun_type="K-IFRS(ì—°ê²°)"):
        """
        finGubun ì½¤ë³´ë°•ìŠ¤ì—ì„œ ê°’ ì„ íƒ
        
        Args:
            finGubun_type (str): "K-IFRS(ì—°ê²°)" ë˜ëŠ” "K-IFRS(ë³„ë„)"
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸ“Š '{finGubun_type}' finGubun ì„ íƒ ì‹œë„ ì¤‘...")
            
            # finGubun ì½¤ë³´ë°•ìŠ¤ ì°¾ê¸°
            selectors = [
                "#finGubun",
                "select[id='finGubun']",
                "select[name='finGubun']",
                "[id*='finGubun']"
            ]
            
            # ê° ì…€ë ‰í„°ë¡œ ì‹œë„
            for selector in selectors:
                try:
                    # ì½¤ë³´ë°•ìŠ¤ê°€ ë³´ì´ëŠ”ì§€ í™•ì¸
                    combo_element = self.page.locator(selector).first
                    if await combo_element.is_visible():
                        # ì½¤ë³´ë°•ìŠ¤ë¥¼ í™”ë©´ì— ìŠ¤í¬ë¡¤
                        await combo_element.scroll_into_view_if_needed()
                        await self.page.wait_for_timeout(500)
                        
                        # ì½¤ë³´ë°•ìŠ¤ì—ì„œ ê°’ ì„ íƒ
                        await combo_element.select_option(label=finGubun_type)
                        print(f"âœ… '{finGubun_type}' finGubun ì„ íƒ ì„±ê³µ!")
                        
                        # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                        await self.page.wait_for_timeout(1500)
                        return True
                        
                except Exception as e:
                    continue
                    
            # JavaScriptë¡œ ì§ì ‘ ì½¤ë³´ë°•ìŠ¤ ì„ íƒ ì‹œë„
            print(f"ğŸ”„ JavaScriptë¡œ '{finGubun_type}' finGubun ì„ íƒ ì‹œë„...")
            
            js_select_script = f"""
            () => {{
                const finGubunSelect = document.getElementById('finGubun') || 
                                     document.querySelector('select[id*="finGubun"]') ||
                                     document.querySelector('select[name*="finGubun"]');
                
                if (finGubunSelect) {{
                    const options = Array.from(finGubunSelect.options);
                    const targetOption = options.find(option => 
                        option.text.includes('{finGubun_type}') || 
                        option.value.includes('{finGubun_type}')
                    );
                    
                    if (targetOption) {{
                        finGubunSelect.value = targetOption.value;
                        
                        // change ì´ë²¤íŠ¸ ë°œìƒ
                        const event = new Event('change', {{ bubbles: true }});
                        finGubunSelect.dispatchEvent(event);
                        
                        return true;
                    }}
                }}
                return false;
            }}
            """
            
            result = await self.page.evaluate(js_select_script)
            if result:
                print(f"âœ… JavaScriptë¡œ '{finGubun_type}' finGubun ì„ íƒ ì„±ê³µ!")
                await self.page.wait_for_timeout(1500)  # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                return True
                
            print(f"âŒ '{finGubun_type}' finGubun ì½¤ë³´ë°•ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ë””ë²„ê¹…: ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ë“¤ í™•ì¸
            print(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ finGubun ì˜µì…˜ë“¤ í™•ì¸ ì¤‘...")
            available_options = await self.page.evaluate("""
            () => {
                const finGubunSelect = document.getElementById('finGubun') || 
                                     document.querySelector('select[id*="finGubun"]') ||
                                     document.querySelector('select[name*="finGubun"]');
                
                if (finGubunSelect) {
                    const options = Array.from(finGubunSelect.options);
                    return options.map(option => ({
                        value: option.value,
                        text: option.text,
                        selected: option.selected
                    }));
                }
                return null;
            }
            """)
            
            if available_options:
                print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ finGubun ì˜µì…˜ë“¤:")
                for i, option in enumerate(available_options):
                    selected_mark = " [ì„ íƒë¨]" if option['selected'] else ""
                    print(f"   {i+1}. {option['text']} (value: {option['value']}){selected_mark}")
            else:
                print(f"âŒ finGubun ì½¤ë³´ë°•ìŠ¤ ìì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
            return False
            
        except Exception as e:
            print(f"âŒ '{finGubun_type}' finGubun ì„ íƒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

    async def select_period_type(self, period_type="ì—°ê°„"):
        """
        ì—°ê°„/ë¶„ê¸° ë¼ë””ì˜¤ ë²„íŠ¼ ì„ íƒ
        
        Args:
            period_type (str): "ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°"
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸ“… '{period_type}' ê¸°ê°„ íƒ€ì… ì„ íƒ ì‹œë„ ì¤‘...")
            
            # ë‹¤ì–‘í•œ ì…€ë ‰í„°ë¡œ ë¼ë””ì˜¤ ë²„íŠ¼ ì°¾ê¸°
            selectors = [
                f"input[type='radio'][value*='{period_type}']",
                f"input[type='radio'] + label:has-text('{period_type}')",
                f"label:has-text('{period_type}') input[type='radio']",
                f"[for*='{period_type}']",
                f"input[id*='{period_type}']",
                f"input[name*='period'][value*='{period_type}']",
                f"input[name*='term'][value*='{period_type}']"
            ]
            
            # ê° ì…€ë ‰í„°ë¡œ ì‹œë„
            for selector in selectors:
                try:
                    element = self.page.locator(selector).first
                    if await element.is_visible():
                        await element.scroll_into_view_if_needed()
                        await self.page.wait_for_timeout(500)
                        await element.click()
                        print(f"âœ… '{period_type}' ë¼ë””ì˜¤ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!")
                        await self.page.wait_for_timeout(1500)  # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                        return True
                except Exception as e:
                    continue
            
            # JavaScriptë¡œ ì§ì ‘ ë¼ë””ì˜¤ ë²„íŠ¼ í´ë¦­ ì‹œë„
            print(f"ğŸ”„ JavaScriptë¡œ '{period_type}' ë¼ë””ì˜¤ ë²„íŠ¼ í´ë¦­ ì‹œë„...")
            
            js_click_script = f"""
            () => {{
                // ë¼ë””ì˜¤ ë²„íŠ¼ ì°¾ê¸°
                const radioButtons = Array.from(document.querySelectorAll('input[type="radio"]'));
                let targetRadio = null;
                
                // value ì†ì„±ì—ì„œ ì°¾ê¸°
                targetRadio = radioButtons.find(radio => 
                    radio.value && radio.value.includes('{period_type}')
                );
                
                // ë¼ë²¨ í…ìŠ¤íŠ¸ì—ì„œ ì°¾ê¸°
                if (!targetRadio) {{
                    for (const radio of radioButtons) {{
                        const label = document.querySelector(`label[for="${{radio.id}}"]`);
                        if (label && label.textContent.includes('{period_type}')) {{
                            targetRadio = radio;
                            break;
                        }}
                        
                        // ë¶€ëª¨ ë¼ë²¨ í™•ì¸
                        const parentLabel = radio.closest('label');
                        if (parentLabel && parentLabel.textContent.includes('{period_type}')) {{
                            targetRadio = radio;
                            break;
                        }}
                    }}
                }}
                
                // í…ìŠ¤íŠ¸ ì£¼ë³€ ë¼ë””ì˜¤ ë²„íŠ¼ ì°¾ê¸°
                if (!targetRadio) {{
                    const spans = Array.from(document.querySelectorAll('span, div, td'));
                    for (const span of spans) {{
                        if (span.textContent && span.textContent.trim() === '{period_type}') {{
                            const nearbyRadio = span.parentElement?.querySelector('input[type="radio"]') ||
                                              span.querySelector('input[type="radio"]') ||
                                              span.previousElementSibling?.querySelector('input[type="radio"]') ||
                                              span.nextElementSibling?.querySelector('input[type="radio"]');
                            if (nearbyRadio) {{
                                targetRadio = nearbyRadio;
                                break;
                            }}
                        }}
                    }}
                }}
                
                if (targetRadio) {{
                    targetRadio.checked = true;
                    targetRadio.click();
                    
                    // change ì´ë²¤íŠ¸ ë°œìƒ
                    const event = new Event('change', {{ bubbles: true }});
                    targetRadio.dispatchEvent(event);
                    
                    return true;
                }}
                return false;
            }}
            """
            
            result = await self.page.evaluate(js_click_script)
            if result:
                print(f"âœ… JavaScriptë¡œ '{period_type}' ë¼ë””ì˜¤ ë²„íŠ¼ í´ë¦­ ì„±ê³µ!")
                await self.page.wait_for_timeout(1500)  # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                return True
                
            print(f"âŒ '{period_type}' ë¼ë””ì˜¤ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        except Exception as e:
            print(f"âŒ '{period_type}' ë¼ë””ì˜¤ ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

    async def click_tab(self, tab_name):
        """
        íˆ¬ìë¶„ì„ íƒ­ í´ë¦­
        
        Args:
            tab_name (str): í´ë¦­í•  íƒ­ ì´ë¦„
            
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            print(f"ğŸ–±ï¸ '{tab_name}' íƒ­ í´ë¦­ ì‹œë„ ì¤‘...")
            
            # ë‹¤ì–‘í•œ ì…€ë ‰í„°ë¡œ íƒ­ ì°¾ê¸°
            selectors = [
                f"text={tab_name}",
                f"a:has-text('{tab_name}')",
                f"span:has-text('{tab_name}')",
                f"button:has-text('{tab_name}')",
                f"td:has-text('{tab_name}')",
                f"div:has-text('{tab_name}')",
                f"[onclick*='{tab_name}']",
                f"[href*='{tab_name}']"
            ]
            
            # ê° ì…€ë ‰í„°ë¡œ ì‹œë„
            for selector in selectors:
                try:
                    # ìš”ì†Œê°€ ë³´ì´ëŠ”ì§€ í™•ì¸
                    element = self.page.locator(selector).first
                    if await element.is_visible():
                        # ìš”ì†Œë¥¼ í™”ë©´ì— ìŠ¤í¬ë¡¤
                        await element.scroll_into_view_if_needed()
                        await self.page.wait_for_timeout(500)
                        
                        # í´ë¦­
                        await element.click()
                        print(f"âœ… '{tab_name}' íƒ­ í´ë¦­ ì„±ê³µ!")
                        
                        # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                        await self.page.wait_for_timeout(1500)
                        return True
                        
                except Exception as e:
                    continue
                    
            # JavaScriptë¡œ ì§ì ‘ í´ë¦­ ì‹œë„
            print(f"ğŸ”„ JavaScriptë¡œ '{tab_name}' íƒ­ í´ë¦­ ì‹œë„...")
            
            js_click_script = f"""
            () => {{
                const elements = Array.from(document.querySelectorAll('*'));
                const targetElement = elements.find(el => 
                    el.textContent && el.textContent.trim() === '{tab_name}' &&
                    (el.tagName === 'A' || el.tagName === 'SPAN' || el.tagName === 'BUTTON' || el.tagName === 'TD')
                );
                
                if (targetElement) {{
                    targetElement.click();
                    return true;
                }}
                return false;
            }}
            """
            
            result = await self.page.evaluate(js_click_script)
            if result:
                print(f"âœ… JavaScriptë¡œ '{tab_name}' íƒ­ í´ë¦­ ì„±ê³µ!")
                await self.page.wait_for_timeout(1500)
                return True
                
            print(f"âŒ '{tab_name}' íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        except Exception as e:
            print(f"âŒ '{tab_name}' íƒ­ í´ë¦­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
            
    async def extract_table_data(self, tab_name, finGubun_type="K-IFRS(ì—°ê²°)"):
        """
        í˜„ì¬ í™”ë©´ì˜ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ (íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ í…Œì´ë¸”ë§Œ)
        
        Args:
            tab_name (str): í˜„ì¬ íƒ­ ì´ë¦„
            finGubun_type (str): finGubun êµ¬ë¶„ê°’ ("K-IFRS(ì—°ê²°)" ë˜ëŠ” "K-IFRS(ë³„ë„)")
            
        Returns:
            pandas.DataFrame: ì¶”ì¶œëœ ë°ì´í„°
        """
        try:
            print(f"ğŸ“Š '{tab_name}' íƒ­ì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            
            # í…Œì´ë¸” ë¡œë”© ëŒ€ê¸°
            await self.page.wait_for_timeout(1500)
            
            # ê°„ë‹¨í•œ í…Œì´ë¸” ê°œìˆ˜ í™•ì¸
            table_count = await self.page.evaluate("""
            () => {
                const tables = document.querySelectorAll('table.gHead01.all-width.data-list');
                return tables.length;
            }
            """)
            
            print(f"ğŸ” í˜ì´ì§€ì—ì„œ ë°œê²¬ëœ target í…Œì´ë¸” ìˆ˜: {table_count}ê°œ")
            
            # íƒ­ë³„ í‚¤ì›Œë“œ ë§¤í•‘ (finGubunì— ë”°ë¼ í™œë™ì„± í‚¤ì›Œë“œ ë³€ê²½)
            if tab_name == 'í™œë™ì„±':
                if finGubun_type == "K-IFRS(ì—°ê²°)":
                    activity_keyword = 'ìê¸°ìë³¸íšŒì „ìœ¨'
                else:  # K-IFRS(ë³„ë„)
                    activity_keyword = 'ì´ìì‚°íšŒì „ìœ¨'
                    
                tab_keywords = {
                    'ìˆ˜ìµì„±': 'ë§¤ì¶œì´ì´ìµë¥ ',
                    'ì„±ì¥ì„±': 'ë§¤ì¶œì•¡ì¦ê°€ìœ¨',
                    'ì•ˆì •ì„±': 'ë¶€ì±„ë¹„ìœ¨',
                    'í™œë™ì„±': activity_keyword
                }
            else:
                tab_keywords = {
                    'ìˆ˜ìµì„±': 'ë§¤ì¶œì´ì´ìµë¥ ',
                    'ì„±ì¥ì„±': 'ë§¤ì¶œì•¡ì¦ê°€ìœ¨',
                    'ì•ˆì •ì„±': 'ë¶€ì±„ë¹„ìœ¨',
                    'í™œë™ì„±': 'ì´ìì‚°íšŒì „ìœ¨'  # ê¸°ë³¸ê°’
                }
            
            keyword = tab_keywords.get(tab_name, '')
            if not keyword:
                print(f"âŒ '{tab_name}' íƒ­ì— ëŒ€í•œ í‚¤ì›Œë“œê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            print(f"ğŸ” '{keyword}' í‚¤ì›Œë“œê°€ í¬í•¨ëœ í…Œì´ë¸”ì„ ì°¾ëŠ” ì¤‘... (finGubun: {finGubun_type})")
            print(f"ğŸ“‹ í˜„ì¬ íƒ­: {tab_name}, ì‚¬ìš©í•  í‚¤ì›Œë“œ: {keyword}")
            
            # JavaScriptë¡œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í…Œì´ë¸” ì°¾ê¸°
            table_data = await self.page.evaluate(f"""
            () => {{
                const keyword = '{keyword}';
                const results = [];
                
                // ëª¨ë“  í…Œì´ë¸” ê²€ì‚¬
                const allTables = document.querySelectorAll('table.gHead01.all-width.data-list');
                console.log('Found all target tables:', allTables.length);
                
                for (const table of allTables) {{
                    // í…Œì´ë¸” ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
                    const tableText = table.textContent;
                    if (tableText.includes(keyword)) {{
                        console.log('Found table with keyword:', keyword);
                        
                        const rows = table.querySelectorAll('tr');
                        if (rows.length > 1) {{
                            const tableData = [];
                            
                            for (const row of rows) {{
                                const cells = row.querySelectorAll('td, th');
                                if (cells.length > 0) {{
                                    const rowData = [];
                                    for (const cell of cells) {{
                                        const text = cell.textContent.trim();
                                        rowData.push(text);
                                    }}
                                    if (rowData.some(cell => cell)) {{
                                        tableData.push(rowData);
                                    }}
                                }}
                            }}
                            
                            if (tableData.length > 1) {{
                                results.push(tableData);
                                console.log('Extracted table data rows:', tableData.length);
                                break; // ì²« ë²ˆì§¸ ë§¤ì¹­ í…Œì´ë¸”ë§Œ ì‚¬ìš©
                            }}
                        }}
                    }}
                }}
                
                if (results.length === 0) {{
                    console.log('No table found with keyword:', keyword);
                    // ëŒ€ì²´: ì²« ë²ˆì§¸ ìœ íš¨í•œ í…Œì´ë¸” ì‚¬ìš©
                    for (const table of allTables) {{
                        const rows = table.querySelectorAll('tr');
                        if (rows.length > 5) {{ // ìµœì†Œ 5í–‰ ì´ìƒì¸ í…Œì´ë¸”
                            const tableData = [];
                            for (const row of rows) {{
                                const cells = row.querySelectorAll('td, th');
                                if (cells.length > 0) {{
                                    const rowData = [];
                                    for (const cell of cells) {{
                                        const text = cell.textContent.trim();
                                        rowData.push(text);
                                    }}
                                    if (rowData.some(cell => cell)) {{
                                        tableData.push(rowData);
                                    }}
                                }}
                            }}
                            if (tableData.length > 1) {{
                                results.push(tableData);
                                console.log('Using fallback table with rows:', tableData.length);
                                break;
                            }}
                        }}
                    }}
                }}
                
                return results;
            }}
            """)
            
            if table_data:
                # ê°€ì¥ ë§ì€ ì»¬ëŸ¼ì„ ê°€ì§„ í…Œì´ë¸” ì„ íƒ (íˆ¬ìë¶„ì„ ë°ì´í„°ëŠ” ì—°ë„ë³„ ì»¬ëŸ¼ì´ ë§ìŒ)
                best_table = max(table_data, key=lambda t: len(t[0]) if t else 0)
                
                if len(best_table) > 1:
                    headers = best_table[0]
                    data_rows = best_table[1:]
                    
                    # ì»¬ëŸ¼ ìˆ˜ ë§ì¶”ê¸°
                    max_cols = max(len(headers), max(len(row) for row in data_rows))
                    
                    # í—¤ë” ì¡°ì • ë° ì¤‘ë³µ ì œê±°
                    while len(headers) < max_cols:
                        headers.append(f'Column_{len(headers)+1}')
                    headers = headers[:max_cols]
                    
                    # ì¤‘ë³µëœ ì»¬ëŸ¼ëª… ì²˜ë¦¬
                    seen = {}
                    for i, header in enumerate(headers):
                        if header in seen:
                            seen[header] += 1
                            headers[i] = f"{header}_{seen[header]}"
                        else:
                            seen[header] = 0
                    
                    # ì»¬ëŸ¼ëª… ì •ë¦¬
                    headers = [self._clean_column_name(header) for header in headers]
                    
                    # ë°ì´í„° í–‰ ì¡°ì •
                    adjusted_data = []
                    for row in data_rows:
                        adjusted_row = row[:max_cols]
                        while len(adjusted_row) < max_cols:
                            adjusted_row.append('')
                        adjusted_data.append(adjusted_row)
                    
                    df = pd.DataFrame(adjusted_data, columns=headers)
                    
                    # ìˆ«ìê°’ì—ì„œ ì½¤ë§ˆ ì œê±°
                    df = self._clean_numeric_values(df)
                    
                    # ê³„ì¸µ êµ¬ì¡° íŒŒì‹± (idì™€ parent_id ì»¬ëŸ¼ ì¶”ê°€)
                    df = self._add_hierarchy_columns(df)
                    
                    print(f"âœ… '{tab_name}' íƒ­ì—ì„œ {len(df)}í–‰ì˜ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
                    return df
                    
            print(f"âŒ '{tab_name}' íƒ­ì—ì„œ í…Œì´ë¸” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
            
        except Exception as e:
            print(f"âŒ '{tab_name}' íƒ­ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame()
    
    def _add_hierarchy_columns(self, df):
        """
        ë°ì´í„°í”„ë ˆì„ì— ê³„ì¸µ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” idì™€ parent_id ì»¬ëŸ¼ì„ ì¶”ê°€
        
        Args:
            df (pandas.DataFrame): ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            
        Returns:
            pandas.DataFrame: id, parent_id ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            if df.empty or len(df.columns) == 0:
                return df
                
            # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ í•­ëª©ëª…ìœ¼ë¡œ ê°€ì •
            item_column = df.columns[0]
            
            # idì™€ parent_id ì»¬ëŸ¼ ì´ˆê¸°í™” (parent_idëŠ” ê³µë°±ìœ¼ë¡œ ì„¤ì •)
            df['id'] = range(1, len(df) + 1)
            df['parent_id'] = ''
            
            # ê³„ì¸µ êµ¬ì¡° íŒŒì‹± - ê°„ë‹¨í•œ ë°©ì‹
            last_parent_id = None  # ê°€ì¥ ìµœê·¼ì˜ "í¼ì¹˜ê¸°" í•­ëª© ID
            
            for idx, row in df.iterrows():
                item_text = str(row[item_column]).strip()
                current_id = row['id']
                
                # "í¼ì¹˜ê¸°"ê°€ ìˆëŠ”ì§€ í™•ì¸ (í…ìŠ¤íŠ¸ ì •ë¦¬ ì „ì—)
                is_parent = self._is_parent_item(item_text)
                
                if is_parent:
                    # "í¼ì¹˜ê¸°"ê°€ ìˆìœ¼ë©´ ìƒìœ„ ê°ì²´ â†’ ë¶€ëª¨ ID ì—…ë°ì´íŠ¸
                    last_parent_id = current_id
                    # ìƒìœ„ ê°ì²´ëŠ” parent_idê°€ ê³µë°± (ìµœìƒìœ„)
                    df.at[idx, 'parent_id'] = ''
                else:
                    # "í¼ì¹˜ê¸°"ê°€ ì—†ìœ¼ë©´ í•˜ìœ„ ê°ì²´ â†’ ê°€ì¥ ìµœê·¼ ë¶€ëª¨ì˜ ìì‹
                    if last_parent_id is not None:
                        df.at[idx, 'parent_id'] = last_parent_id
                    else:
                        df.at[idx, 'parent_id'] = ''
                
                # ë§ˆì§€ë§‰ì— í…ìŠ¤íŠ¸ ì •ë¦¬ (í¼ì¹˜ê¸° ì œê±°)
                clean_text = self._clean_item_text(item_text)
                df.at[idx, item_column] = clean_text
                    
            # ì»¬ëŸ¼ ìˆœì„œ ì¬ì •ë ¬ (id, parent_idë¥¼ ë§¨ ì•ìœ¼ë¡œ)
            cols = ['id', 'parent_id'] + [col for col in df.columns if col not in ['id', 'parent_id']]
            df = df[cols]
            
            # ê³„ì¸µ êµ¬ì¡° ë¶„ì„ ê²°ê³¼ ì¶œë ¥
            parent_count = len([x for x in df['parent_id'] if x != ''])
            parent_items = len([True for idx, row in df.iterrows() if self._is_parent_item(str(row[item_column]) + ("í¼ì¹˜ê¸°" if row.get('parent_id') != '' else ""))])
            
            print(f"ğŸ”— ê³„ì¸µ êµ¬ì¡° íŒŒì‹± ì™„ë£Œ:")
            print(f"   - í•˜ìœ„ í•­ëª©: {parent_count}ê°œ")
            print(f"   - ìƒìœ„ í•­ëª©: {len(df) - parent_count}ê°œ")
            
            # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ í•­ëª©ì˜ ê³„ì¸µ êµ¬ì¡° ì¶œë ¥
            if len(df) > 0:
                print(f"ğŸ“‹ ê³„ì¸µ êµ¬ì¡° ì˜ˆì‹œ (ì²˜ìŒ 5ê°œ):")
                for i, (idx, row) in enumerate(df.head(5).iterrows()):
                    item_name = str(row[item_column])[:30] + "..." if len(str(row[item_column])) > 30 else str(row[item_column])
                    parent_info = f"â†’ ë¶€ëª¨ID: {row['parent_id']}" if row['parent_id'] != '' else "â†’ ìµœìƒìœ„"
                    print(f"   {row['id']:2d}. {item_name:35s} {parent_info}")
            
            return df
            
        except Exception as e:
            print(f"âŒ ê³„ì¸µ êµ¬ì¡° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒì‹œ ê¸°ë³¸ idë§Œ ì¶”ê°€í•˜ê³  ë°˜í™˜
            df['id'] = range(1, len(df) + 1)
            df['parent_id'] = ''
            return df
    
    def _clean_numeric_values(self, df):
        """
        DataFrameì˜ ìˆ«ìê°’ì—ì„œ ì½¤ë§ˆë¥¼ ì œê±°
        
        Args:
            df (pd.DataFrame): ì›ë³¸ DataFrame
            
        Returns:
            pd.DataFrame: ì½¤ë§ˆê°€ ì œê±°ëœ DataFrame
        """
        try:
            # ëª¨ë“  ì»¬ëŸ¼ì— ëŒ€í•´ ì½¤ë§ˆ ì œê±° (id, parent_id, company_codeëŠ” ì œì™¸)
            for col in df.columns:
                if col not in ['id', 'parent_id', 'company_code'] and len(df.columns) > 1:
                    # ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì½¤ë§ˆ ì œê±°
                    df[col] = df[col].astype(str).str.replace(',', '', regex=False)
            
            print(f"ğŸ§¹ ìˆ«ìê°’ ì½¤ë§ˆ ì œê±° ì™„ë£Œ")
            return df
            
        except Exception as e:
            print(f"âš ï¸ ìˆ«ìê°’ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return df
    
    def _clean_column_name(self, column_name):
        """
        ì»¬ëŸ¼ëª…ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            column_name (str): ì›ë³¸ ì»¬ëŸ¼ëª…
            
        Returns:
            str: ì •ë¦¬ëœ ì»¬ëŸ¼ëª…
        """
        if not column_name:
            return ""
        
        # 1. ì—°ê°„ì»¨ì„¼ì„œìŠ¤ë³´ê¸° íŒ¨í„´ ì œê±°: "\n...ë³´ê¸°" -> ""
        if "ì—°ê°„ì»¨ì„¼ì„œìŠ¤ë³´ê¸°" in column_name:
            column_name = re.sub(r'\n.*?ë³´ê¸°', '', column_name)
        
        # 2. ì—°ê°„ì»¨ì„¼ì„œìŠ¤ë‹«ê¸° íŒ¨í„´ ë³€í™˜: "\n...ë‹«ê¸°" -> "(ì—°ê°„ì»¨ì„¼ì„œìŠ¤)"
        if "ì—°ê°„ì»¨ì„¼ì„œìŠ¤ë‹«ê¸°" in column_name:
            column_name = re.sub(r'\n.*?ë‹«ê¸°', '(ì—°ê°„ì»¨ì„¼ì„œìŠ¤)', column_name)
        
        # 3. _1 íŒ¨í„´ ë³€í™˜: "_1" -> "(ì—°ê°„ì»¨ì„¼ì„œìŠ¤)"
        if column_name.endswith('_1'):
            column_name = column_name.replace('_1', '(ì—°ê°„ì»¨ì„¼ì„œìŠ¤)')
        
        # 4. ê¸°íƒ€ ê°œí–‰ë¬¸ìì™€ íƒ­ ì •ë¦¬
        column_name = re.sub(r'[\n\t\r]+', ' ', column_name)
        
        # 5. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
        column_name = re.sub(r'\s+', ' ', column_name)
        
        return column_name.strip()
    
    def _clean_item_text(self, text):
        """
        í•­ëª© í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        
        Args:
            text (str): ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            str: ì •ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        if not text:
            return text
            
        # "í¼ì¹˜ê¸°" í…ìŠ¤íŠ¸ì™€ ê´€ë ¨ ë¬¸ì ì œê±°
        clean_text = text.replace('í¼ì¹˜ê¸°', '').strip()
        
        # íƒ­ê³¼ ê³¼ë„í•œ ê³µë°± ì •ë¦¬
        clean_text = ' '.join(clean_text.split())
        
        # ì ‘ê¸°/í¼ì¹˜ê¸° ê´€ë ¨ íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_text = clean_text.replace('â–¼', '').replace('â–²', '').replace('â–³', '').replace('â–½', '')
        clean_text = clean_text.replace('+', '').replace('-', '').strip()
        
        return clean_text
    
    def _is_parent_item(self, text):
        """
        í•´ë‹¹ í•­ëª©ì´ ìƒìœ„ í•­ëª©(ì ‘ê¸°/í¼ì¹˜ê¸°ê°€ ê°€ëŠ¥í•œ í•­ëª©)ì¸ì§€ íŒë‹¨
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            bool: ìƒìœ„ í•­ëª© ì—¬ë¶€
        """
        if not text:
            return False
            
        # "í¼ì¹˜ê¸°" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìƒìœ„ í•­ëª©
        if 'í¼ì¹˜ê¸°' in text:
            return True
            
        # ì ‘ê¸°/í¼ì¹˜ê¸° ê´€ë ¨ íŠ¹ìˆ˜ë¬¸ìê°€ ìˆìœ¼ë©´ ìƒìœ„ í•­ëª©
        expand_collapse_chars = ['â–¼', 'â–²', 'â–³', 'â–½', '+', '-']
        if any(char in text for char in expand_collapse_chars):
            return True
            
        # íŠ¹ì • íŒ¨í„´ì˜ í•­ëª©ëª… (ì˜ˆ: "ìˆ˜ìµì„± ì§€í‘œ", "ì„±ì¥ì„± ë¶„ì„" ë“±)
        parent_keywords = ['ì§€í‘œ', 'ë¶„ì„', 'ë¹„ìœ¨', 'í˜„í™©', 'ìƒí™©', 'ë‚´ì—­']
        clean_text = self._clean_item_text(text)
        if any(keyword in clean_text for keyword in parent_keywords):
            return True
            
        return False

    def extract_year_month_from_data(self, df):
        """
        í¬ë¡¤ë§ëœ ë°ì´í„°ì—ì„œ ì‹¤ì œ ì—°ë„/ì›” ì¶”ì¶œ
        
        Args:
            df (pd.DataFrame): í¬ë¡¤ë§ëœ ë°ì´í„°
            
        Returns:
            tuple: (year, month) ë˜ëŠ” (None, None)
        """
        if df.empty or 'yyyy' not in df.columns or 'month' not in df.columns:
            return None, None
        
        # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ì—°ë„/ì›” ì°¾ê¸°
        year_counts = df['yyyy'].value_counts()
        month_counts = df['month'].value_counts()
        
        if not year_counts.empty and not month_counts.empty:
            most_common_year = year_counts.index[0]
            most_common_month = month_counts.index[0]
            
            print(f"ğŸ“… í¬ë¡¤ë§ëœ ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ì—°ë„/ì›”: {most_common_year}/{most_common_month}")
            return most_common_year, most_common_month
        
        return None, None

    def save_data_by_yyyymm(self, df, output_dir, period_type, s3_bucket=None, save_local=True):
        """
        yyyymmë³„ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì €ì¥
        
        Args:
            df (pd.DataFrame): ë³€í™˜ëœ ë°ì´í„°
            output_dir (str): ì¶œë ¥ ë””ë ‰í† ë¦¬
            period_type (str): "ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°"
            s3_bucket (str): S3 ë²„í‚·ëª… (ì„ íƒì‚¬í•­)
            save_local (bool): ë¡œì»¬ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        if df.empty or 'yyyy' not in df.columns or 'month' not in df.columns:
            print("âŒ yyyy, month ì»¬ëŸ¼ì´ ì—†ì–´ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # yyyymm ì»¬ëŸ¼ ìƒì„±
        df['yyyymm'] = df['yyyy'].astype(str) + df['month'].astype(str).str.zfill(2)
        
        # ê³ ìœ í•œ yyyymm ê°’ë“¤ ì°¾ê¸°
        unique_yyyymm = sorted(df['yyyymm'].unique())
        print(f"ğŸ“… ë°œê²¬ëœ yyyymm: {unique_yyyymm}")
        
        # ê°€ì¥ í° yyyymm ì°¾ê¸° (ë¶„ì„ ë°ì´í„°ìš©)
        max_yyyymm = max(unique_yyyymm)
        print(f"ğŸ“… ë¶„ì„ ë°ì´í„°(ì „ë…„ëŒ€ë¹„/ì „ë¶„ê¸°ëŒ€ë¹„)ê°€ í¬í•¨ë  ìµœì‹  ë…„ì›”: {max_yyyymm}")

        # ê° yyyymmë³„ë¡œ ë°ì´í„° ë¶„ë¦¬í•˜ì—¬ ì €ì¥
        for yyyymm in unique_yyyymm:
            # í•´ë‹¹ yyyymm ë°ì´í„°ë§Œ í•„í„°ë§
            yyyymm_data = df[df['yyyymm'] == yyyymm].copy()

            # ë¶„ì„ ë°ì´í„°ëŠ” ìµœì‹  ë…„ì›”ì—ë§Œ í¬í•¨
            if yyyymm != max_yyyymm and 'column_type' in yyyymm_data.columns:
                # ìµœì‹  ë…„ì›”ì´ ì•„ë‹ˆë©´ ë¶„ì„ ë°ì´í„° ì œì™¸
                filtered_df = yyyymm_data[yyyymm_data['column_type'] != 'analysis_data'].copy()
                excluded_count = len(yyyymm_data) - len(filtered_df)
                if excluded_count > 0:
                    print(f"ğŸ“Š {yyyymm}: ë¶„ì„ ë°ì´í„° {excluded_count}ê°œ ì œì™¸ (ìµœì‹  ë…„ì›” {max_yyyymm}ì—ë§Œ í¬í•¨)")
            else:
                # ìµœì‹  ë…„ì›”ì´ê±°ë‚˜ column_type ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ëª¨ë“  ë°ì´í„° í¬í•¨
                filtered_df = yyyymm_data.copy()
            
            if not filtered_df.empty:
                # íŒŒì¼ëª… ìƒì„±
                period_suffix = "_annual" if period_type == "ì—°ê°„" else "_quarterly"
                filename = f"{output_dir}/{yyyymm}_all_companies{period_suffix}_transformed.csv"
                
                # ë¡œì»¬ CSV ì €ì¥ (save_localì´ Trueì¸ ê²½ìš°)
                if save_local:
                    # ì €ì¥ ì „ ë°ì´í„° íƒ€ì… ì¡°ì •: value ì»¬ëŸ¼ë§Œ ìˆ«ìë¡œ, ë‚˜ë¨¸ì§€ëŠ” ë¬¸ìì—´ë¡œ
                    df_to_save = filtered_df.copy()
                    for col in df_to_save.columns:
                        if col != 'value':
                            df_to_save[col] = df_to_save[col].astype(str)
                    
                    df_to_save.to_csv(filename, index=False, encoding='utf-8-sig')
                    print(f"ğŸ’¾ {yyyymm} ë¡œì»¬ ë°ì´í„° ì €ì¥: {filename} ({len(filtered_df)}í–‰)")
                else:
                    print(f"â­ï¸ {yyyymm} ë¡œì»¬ ì €ì¥ ìƒëµ (save_local=False)")
                
                # S3 ì—…ë¡œë“œ (ë²„í‚·ì´ ì§€ì •ëœ ê²½ìš°)
                if s3_bucket:
                    try:
                        # ê¸°ê°„ íƒ€ì…ì„ ì˜ì–´ë¡œ ë³€í™˜
                        period_type_en = "annual" if period_type == "ì—°ê°„" else "quarter"
                        
                        # yyyymmì—ì„œ ì—°ë„ì™€ ì›” ì¶”ì¶œ
                        year = yyyymm[:4]
                        month = yyyymm[4:6]
                        
                        # S3 í‚¤ ìƒì„±
                        s3_key = generate_s3_key(period_type_en, year, month)
                        
                        print(f"ğŸ“¤ S3 ì—…ë¡œë“œ ì¤€ë¹„: s3://{s3_bucket}/{s3_key}")
                        print(f"ğŸ“… ë°ì´í„° ì—°ë„/ì›”: {year}/{month}")
                        
                        # S3 ì—…ë¡œë“œ (ë¡œì»¬ íŒŒì¼ì´ ìˆì–´ì•¼ ì—…ë¡œë“œ ê°€ëŠ¥)
                        if save_local:
                            s3_upload_result = upload_file_to_s3(filename, s3_bucket, s3_key)
                            
                            if s3_upload_result.get("success"):
                                print(f"âœ… S3 ì—…ë¡œë“œ ì„±ê³µ: {s3_upload_result['s3_url']}")
                                print(f"ğŸ“¦ íŒŒì¼ í¬ê¸°: {s3_upload_result['size']} bytes")
                            else:
                                print(f"âŒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {s3_upload_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                        else:
                            print(f"âš ï¸ S3 ì—…ë¡œë“œ ê±´ë„ˆëœ€: ë¡œì»¬ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (save_local=False)")
                            
                    except Exception as e:
                        print(f"âŒ S3 ì—…ë¡œë“œ ê³¼ì •ì—ì„œ ì˜¤ë¥˜: {str(e)}")
            else:
                print(f"âš ï¸ {yyyymm} ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ì €ì¥í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            
    async def cleanup(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ ë° ì •ë¦¬"""
        try:
            if self.page:
                await self.page.close()
            if hasattr(self, 'context') and self.context:
                await self.context.close()
            if self.browser:
                await self.browser.close()
            if hasattr(self, 'playwright'):
                await self.playwright.stop()
            print("ğŸ§¹ ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    async def close_browser(self):
        """ë¸Œë¼ìš°ì € ì •ë¦¬ (ë³„ì¹­ ë©”ì„œë“œ)"""
        await self.cleanup()
            
    async def _crawl_single_company(self, url, company_code, company_name, period_type="ì—°ê°„"):
        """
        ë‹¨ì¼ íšŒì‚¬ í¬ë¡¤ë§ (ë¸Œë¼ìš°ì € ì¬ì‚¬ìš©)
        
        Args:
            url (str): í¬ë¡¤ë§í•  URL
            company_code (str): íšŒì‚¬ ì½”ë“œ
            company_name (str): íšŒì‚¬ëª…
            period_type (str): "ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°"
            
        Returns:
            dict: í¬ë¡¤ë§ ê²°ê³¼
        """
        try:
            # í˜ì´ì§€ ì´ë™
            await self.navigate_to_page(url)
            
            # ê¸°ê°„ íƒ€ì… ì„ íƒ (ì—°ê°„/ë¶„ê¸°)
            print(f"ğŸ“… {company_name}: ê¸°ê°„ íƒ€ì… '{period_type}' ì„ íƒ ì¤‘...")
            if period_type == "annual":
                period_type = "ì—°ê°„"
            elif period_type == "quarter":
                period_type = "ë¶„ê¸°"
            
            period_selected = await self.select_period_type(period_type)
            if not period_selected:
                print(f"âš ï¸ {company_name}: '{period_type}' ê¸°ê°„ íƒ€ì… ì„ íƒì— ì‹¤íŒ¨í–ˆì§€ë§Œ í¬ë¡¤ë§ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            
            # finGubun êµ¬ë¶„ê°’ë“¤
            finGubun_types = ['K-IFRS(ì—°ê²°)', 'K-IFRS(ë³„ë„)']
            tabs = ['ìˆ˜ìµì„±', 'ì„±ì¥ì„±', 'ì•ˆì •ì„±', 'í™œë™ì„±']
            results = {}
            
            # finGubunë³„ë¡œ í¬ë¡¤ë§
            for finGubun_idx, finGubun_type in enumerate(finGubun_types):
                print(f"\n{'='*50}")
                print(f"[{finGubun_idx+1}/2] {company_name}: '{finGubun_type}' í¬ë¡¤ë§ ì‹œì‘")
                print(f"{'='*50}")
                
                # finGubun ì„ íƒ
                finGubun_selected = await self.select_finGubun(finGubun_type)
                if not finGubun_selected:
                    print(f"âš ï¸ {company_name}: '{finGubun_type}' finGubun ì„ íƒì— ì‹¤íŒ¨í–ˆì§€ë§Œ í¬ë¡¤ë§ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                    # finGubun ì„ íƒ ì‹¤íŒ¨ ì‹œì—ë„ íƒ­ í¬ë¡¤ë§ì„ ì‹œë„í•´ë³´ì
                else:
                    print(f"âœ… {company_name}: '{finGubun_type}' finGubun ì„ íƒ ì„±ê³µ!")
                
                # ê° íƒ­ë³„ë¡œ í¬ë¡¤ë§
                for i, tab in enumerate(tabs):
                    print(f"[{i+1}/4] {finGubun_type} - {tab} íƒ­ í¬ë¡¤ë§ ì¤‘...")
                    
                    if await self.click_tab(tab):
                        df = await self.extract_table_data(tab, finGubun_type)
                        if not df.empty:
                            # finGubun ì •ë³´ë¥¼ ë°ì´í„°ì— ì¶”ê°€ (ì¤‘ë³µ ì²´í¬)
                            if 'finGubun' not in df.columns:
                                if len(df.columns) > 0:
                                    df.insert(0, 'finGubun', finGubun_type)
                                else:
                                    df['finGubun'] = finGubun_type
                            
                            # ê²°ê³¼ ì €ì¥ (í‚¤ì— finGubun í¬í•¨)
                            result_key = f"{finGubun_type}_{tab}"
                            results[result_key] = df
                            print(f"âœ… {finGubun_type} - {tab}: {len(df)}í–‰")
                        else:
                            print(f"âŒ {finGubun_type} - {tab}: ë°ì´í„° ì—†ìŒ")
                            print(f"ğŸ” {finGubun_type} - {tab}: ë¹ˆ í…Œì´ë¸”ì¸ì§€ í™•ì¸ ì¤‘...")
                            # ë¹ˆ í…Œì´ë¸”ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ ì¶œë ¥
                    else:
                        print(f"âŒ {finGubun_type} - {tab}: íƒ­ í´ë¦­ ì‹¤íŒ¨")
                    
                    # íƒ­ ê°„ ëŒ€ê¸°
                    await self.page.wait_for_timeout(1000)
                
                # finGubun êµ¬ë¶„ ê°„ ëŒ€ê¸°
                if finGubun_idx < len(finGubun_types) - 1:
                    print(f"â³ ë‹¤ìŒ finGubun í¬ë¡¤ë§ì„ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°...")
                    await self.page.wait_for_timeout(1000)
                
            return results
            
        except Exception as e:
            print(f"âŒ {company_name} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    
            
    
    
    def _extract_data_type_from_column(self, column_name):
        """
        ì»¬ëŸ¼ëª…ì—ì„œ ë°ì´í„° íƒ€ì…ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (finGubun ê°’ì—ì„œ ì—°ê²°/ë³„ë„ë§Œ ì¶”ì¶œ)

        Args:
            column_name (str): ì»¬ëŸ¼ëª… (ì˜ˆ: "2020/12(IFRSì—°ê²°)")

        Returns:
            str: ë°ì´í„° íƒ€ì… (ì˜ˆ: "ì—°ê²°", "ë³„ë„")
        """
        try:
            if not column_name or '(' not in column_name:
                return 'ì—°ê²°'  # ê¸°ë³¸ê°’

            import re

            # IFRS/GAAP ê´€ë ¨ ê´„í˜¸ ë‚´ìš©ì—ì„œ ì—°ê²°/ë³„ë„ ì¶”ì¶œ
            ifrs_pattern = r'\(([^()]*(?:IFRS|GAAP)[^()]*)\)'
            matches = re.findall(ifrs_pattern, column_name)

            if matches:
                data_type = matches[0]  # ì²« ë²ˆì§¸ IFRS ê´€ë ¨ ë§¤ì¹˜

                # ì—°ê²°/ë³„ë„ë§Œ ì¶”ì¶œ
                if 'ì—°ê²°' in data_type:
                    return 'ì—°ê²°'
                elif 'ë³„ë„' in data_type:
                    return 'ë³„ë„'
                else:
                    return 'ì—°ê²°'  # ê¸°ë³¸ê°’

            # IFRS íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ê´„í˜¸ì—ì„œ ì—°ê²°/ë³„ë„ ì°¾ê¸°
            first_paren_content = re.search(r'\((.*?)\)', column_name)
            if first_paren_content:
                content = first_paren_content.group(1)

                # ì—°ê²°/ë³„ë„ í‚¤ì›Œë“œ ê²€ìƒ‰
                if 'ì—°ê²°' in content:
                    return 'ì—°ê²°'
                elif 'ë³„ë„' in content:
                    return 'ë³„ë„'

            return 'ì—°ê²°'  # ê¸°ë³¸ê°’

        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° íƒ€ì… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return 'ì—°ê²°'  # ê¸°ë³¸ê°’
    
    def transform_to_row_format(self, combined_df, period_type="ì—°ê°„"):
        """
        ì»¬ëŸ¼ ê¸°ë°˜ ë°ì´í„°ë¥¼ row ê¸°ë°˜ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë©”ì†Œë“œ

        Args:
            combined_df (pd.DataFrame): í¬ë¡¤ë§ëœ ì›ë³¸ ë°ì´í„°
            period_type (str): ì¡°íšŒ ê¸°ê°„ íƒ€ì… ("ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°")

        Returns:
            pd.DataFrame: ë³€í™˜ëœ ë°ì´í„°
        """
        try:
            print(f"ğŸ“Š ë°ì´í„° ë³€í™˜ ì‹œì‘: {combined_df.shape}")
            
            # ë³€í™˜í•  ì»¬ëŸ¼ë“¤ ì‹ë³„
            # 1. ì—°ë„ ì»¬ëŸ¼ë“¤ (yyyy/mm íŒ¨í„´ì´ ìˆëŠ” ì»¬ëŸ¼ - ì—°ê²°/ë³„ë„ êµ¬ë¶„ ì—†ì´ ëª¨ë“  ì¬ë¬´ ë°ì´í„°)
            import re
            year_pattern = r'\d{4}/\d{2}'
            year_columns = [col for col in combined_df.columns if re.search(year_pattern, col)]
            
            # 2. ë¶„ì„ ì»¬ëŸ¼ë“¤ (ê¸°ê°„ íƒ€ì…ì— ë”°ë¼ ë¶„ê¸°/ì—°ê°„ êµ¬ë¶„)
            if period_type == "ë¶„ê¸°":
                # ë¶„ê¸° ì¡°íšŒ: QoQ, ì „ë¶„ê¸°ëŒ€ë¹„ ë“± ë¶„ê¸° ê´€ë ¨ ë¶„ì„ ì»¬ëŸ¼ë§Œ
                analysis_keywords = ['QoQ', 'ì „ë¶„ê¸°ëŒ€ë¹„', 'ë¶„ê¸°ì¦ê°ë¥ ']
            else:
                # ì—°ê°„ ì¡°íšŒ: YoY, ì „ë…„ëŒ€ë¹„ ë“± ì—°ê°„ ê´€ë ¨ ë¶„ì„ ì»¬ëŸ¼ë§Œ
                analysis_keywords = ['YoY', 'ì „ë…„ëŒ€ë¹„', 'ì¦ê°ë¥ ', 'CAGR']

            analysis_columns = [col for col in combined_df.columns if any(keyword in col for keyword in analysis_keywords)]
            
            # 3. ì „ì²´ ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼
            target_columns = year_columns + analysis_columns
            
            print(f"ğŸ” ë³€í™˜í•  ì—°ë„ ì»¬ëŸ¼ë“¤: {year_columns}")
            print(f"ğŸ“ˆ ë³€í™˜í•  ë¶„ì„ ì»¬ëŸ¼ë“¤: {analysis_columns}")
            print(f"ğŸ“Š ì „ì²´ ë³€í™˜ ëŒ€ìƒ: {len(target_columns)}ê°œ ì»¬ëŸ¼")
            
            if not target_columns:
                print("âŒ ë³€í™˜í•  ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # ë°ì´í„° ë³€í™˜ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸
            transformed_data = []
            
            print("ğŸ”„ ë°ì´í„° ë³€í™˜ ì¤‘...")
            
            # ê°€ì¥ í° ì—°ë„/ì›” ì°¾ê¸° (ë¶„ì„ ë°ì´í„° ë§¤í•‘ìš©) - ì •ê·œì‹ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ
            max_year = ''
            max_month = ''
            for year_col in year_columns:
                year_match = re.search(year_pattern, year_col)
                if year_match:
                    year_period = year_match.group()  # "2024/09"
                    yy, mm = year_period.split('/')
                    if yy.isdigit() and (not max_year or yy > max_year):
                        max_year = yy
                        max_month = mm
            
            print(f"ğŸ“… ë¶„ì„ ë°ì´í„° ë§¤í•‘ ê¸°ì¤€: {max_year}/{max_month}")
            
            # ë¨¼ì € ì—°ë„ ì»¬ëŸ¼ë“¤ë§Œ ì²˜ë¦¬ (ëª¨ë“  í–‰ì—ì„œ)
            for _, row in combined_df.iterrows():
                for target_col in year_columns:
                    # ì—°ë„ ì»¬ëŸ¼ ì²˜ë¦¬ - ì •ê·œì‹ìœ¼ë¡œ yyyy/mm íŒ¨í„´ ì¶”ì¶œ
                    year_match = re.search(year_pattern, target_col)
                    if year_match:
                        year_period = year_match.group()  # "2024/09"
                        yy, mm = year_period.split('/')
                    else:
                        yy, mm = '', ''
                    data_type = self._extract_data_type_from_column(target_col)
                    # period_typeì— ë”°ë¼ column_type êµ¬ë¶„
                    column_type = 'period_data' if period_type == "ë¶„ê¸°" else 'year_data'
                    # value_type ê²°ì • (Eê°€ ìˆìœ¼ë©´ Expected, ì—†ìœ¼ë©´ Real)
                    value_type = 'Expected' if '(E)' in target_col else 'Real'

                    # ê°’ì´ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                    value = row[target_col]
                    if pd.notna(value) and str(value).strip() != '':
                        # ì¡°íšŒêµ¬ë¶„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
                        inquiry_type = row.get('search_type', 'ì—°ê°„')

                        # ê¸°ë³¸ í–‰ ë°ì´í„°
                        transformed_row = {
                            'tab': row['tab'],
                            'search_type': inquiry_type,
                            'id': row['id'],
                            'parent_id': row['parent_id'],
                            'item': row['í•­ëª©'],
                            'column_name': target_col,  # ì›ë³¸ ì»¬ëŸ¼ëª… ì¶”ê°€
                            'column_type': column_type,  # ì»¬ëŸ¼ ìœ í˜• ì¶”ê°€
                            'yyyy': yy,
                            'month': mm,
                            'value': value,
                            'value_type': value_type,  # Expected/Real êµ¬ë¶„
                            'data_type': data_type,
                            'crawl_time': datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S") # KST ì‹œê°„ ì¶”ê°€
                        }

                        # company_codeê°€ ìˆìœ¼ë©´ ì¶”ê°€ (6ìë¦¬ ë¬¸ìì—´ë¡œ ë³´ì¥)
                        if 'company_code' in combined_df.columns:
                            company_code = str(row['company_code']).zfill(6)
                            transformed_row['company_code'] = company_code
                        else:
                            # ë‹¨ì¼ íšŒì‚¬ í¬ë¡¤ë§ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                            transformed_row['company_code'] = '004150'

                        # company_nameì´ ìˆìœ¼ë©´ ì¶”ê°€
                        if 'company_name' in combined_df.columns:
                            transformed_row['company_name'] = row['company_name']
                        else:
                            # ë‹¨ì¼ íšŒì‚¬ í¬ë¡¤ë§ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                            transformed_row['company_name'] = 'í•œì†”í™€ë”©ìŠ¤'

                        # finGubunì´ ìˆìœ¼ë©´ ì¶”ê°€
                        if 'finGubun' in combined_df.columns:
                            transformed_row['finGubun'] = row['finGubun']
                        else:
                            # finGubunì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                            transformed_row['finGubun'] = 'K-IFRS(ì—°ê²°)'

                        transformed_data.append(transformed_row)

            # ë¶„ì„ ì»¬ëŸ¼ë“¤ì€ ìµœì‹  ë…„ì›”ì—ë§Œ ì¶”ê°€ (í•œ ë²ˆë§Œ)
            if analysis_columns:
                print(f"ğŸ“Š ë¶„ì„ ë°ì´í„°ëŠ” ìµœì‹  ë…„ì›” {max_year}/{max_month}ì—ë§Œ ì¶”ê°€ë©ë‹ˆë‹¤.")
                for _, row in combined_df.iterrows():
                    for target_col in analysis_columns:
                        # ë¶„ì„ ì»¬ëŸ¼ ì²˜ë¦¬ (ì „ë…„ëŒ€ë¹„ ë“±) - ê°€ì¥ í° ì—°ë„/ì›”ì— ë§¤í•‘
                        yy = max_year
                        mm = max_month
                        data_type = self._extract_data_type_from_column(target_col) if '(' in target_col else 'analysis'
                        column_type = 'analysis_data'
                        # ë¶„ì„ ë°ì´í„°ëŠ” ëª¨ë‘ Real (ì‹¤ì œ ê³„ì‚°ëœ ê°’)
                        value_type = 'Real'

                        # ê°’ì´ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ë§Œ ì¶”ê°€
                        value = row[target_col]
                        if pd.notna(value) and str(value).strip() != '':
                            # ì¡°íšŒêµ¬ë¶„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
                            inquiry_type = row.get('search_type', 'ì—°ê°„')

                            # ê¸°ë³¸ í–‰ ë°ì´í„°
                            transformed_row = {
                                'tab': row['tab'],
                                'search_type': inquiry_type,
                                'id': row['id'],
                                'parent_id': row['parent_id'],
                                'item': row['í•­ëª©'],
                                'column_name': target_col,  # ì›ë³¸ ì»¬ëŸ¼ëª… ì¶”ê°€
                                'column_type': column_type,  # ì»¬ëŸ¼ ìœ í˜• ì¶”ê°€
                                'yyyy': yy,
                                'month': mm,
                                'value': value,
                                'value_type': value_type,  # Expected/Real êµ¬ë¶„
                                'data_type': data_type,
                                'crawl_time': datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S") # KST ì‹œê°„ ì¶”ê°€
                            }

                            # company_codeê°€ ìˆìœ¼ë©´ ì¶”ê°€ (6ìë¦¬ ë¬¸ìì—´ë¡œ ë³´ì¥)
                            if 'company_code' in combined_df.columns:
                                company_code = str(row['company_code']).zfill(6)
                                transformed_row['company_code'] = company_code
                            else:
                                # ë‹¨ì¼ íšŒì‚¬ í¬ë¡¤ë§ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                                transformed_row['company_code'] = '004150'

                            # company_nameì´ ìˆìœ¼ë©´ ì¶”ê°€
                            if 'company_name' in combined_df.columns:
                                transformed_row['company_name'] = row['company_name']
                            else:
                                # ë‹¨ì¼ íšŒì‚¬ í¬ë¡¤ë§ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                                transformed_row['company_name'] = 'í•œì†”í™€ë”©ìŠ¤'

                            # finGubunì´ ìˆìœ¼ë©´ ì¶”ê°€
                            if 'finGubun' in combined_df.columns:
                                transformed_row['finGubun'] = row['finGubun']
                            else:
                                # finGubunì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                                transformed_row['finGubun'] = 'K-IFRS(ì—°ê²°)'

                            transformed_data.append(transformed_row)
            
            if not transformed_data:
                print("âŒ ë³€í™˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return pd.DataFrame()
            
            # ìƒˆë¡œìš´ DataFrame ìƒì„±
            transformed_df = pd.DataFrame(transformed_data)
            
            # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬ - ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            print(f"ğŸ” ë³€í™˜ëœ DataFrameì˜ ì‹¤ì œ ì»¬ëŸ¼ë“¤: {list(transformed_df.columns)}")
            
            desired_columns = ['company_code', 'company_name', 'finGubun', 'tab', 'search_type', 'id', 'parent_id', 'item', 'column_name', 'column_type', 'yyyy', 'month', 'value', 'value_type', 'data_type', 'crawl_time']
            available_columns = [col for col in desired_columns if col in transformed_df.columns]
            
            print(f"ğŸ¯ ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤: {available_columns}")
            
            if available_columns:
                transformed_df = transformed_df[available_columns]
            else:
                print("âš ï¸ ì›í•˜ëŠ” ì»¬ëŸ¼ì´ ì—†ì–´ ì›ë³¸ ì»¬ëŸ¼ ìˆœì„œë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
            
            print(f"âœ… ë³€í™˜ ì™„ë£Œ: {transformed_df.shape}")
            print(f"ğŸ“ˆ ì´ íšŒì‚¬ ìˆ˜: {transformed_df['company_code'].nunique()}")
            print(f"ğŸ“Š ì´ ì¬ë¬´ í•­ëª© ìˆ˜: {transformed_df['item'].nunique()}")
            print(f"ğŸ“… í¬í•¨ëœ ì—°ë„: {sorted([y for y in transformed_df['yyyy'].unique() if y])}")
            print(f"ğŸ” ì¡°íšŒêµ¬ë¶„: {sorted(transformed_df['search_type'].unique())}")
            print(f"ğŸ“‹ finGubun êµ¬ë¶„: {sorted(transformed_df['finGubun'].unique())}" if 'finGubun' in transformed_df.columns else "ğŸ“‹ finGubun êµ¬ë¶„: ì •ë³´ ì—†ìŒ")
            print(f"ğŸ“‹ ì»¬ëŸ¼ ìœ í˜•: {sorted(transformed_df['column_type'].unique())}")
            print(f"ğŸ’ ê°’ ìœ í˜•: {sorted(transformed_df['value_type'].unique())}")
            print(f"ğŸ·ï¸ ë°ì´í„° íƒ€ì…: {sorted(transformed_df['data_type'].unique())}")
            print(f"ğŸ“ ì´ ë°ì´í„° í¬ì¸íŠ¸: {len(transformed_df)}")
            
            return transformed_df
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.DataFrame()
            
            




async def crawl_multiple_stocks(stocks_data, output_dir="./crawl_results", period_type="ì—°ê°„", s3_bucket=None, save_local=True):
    """
    ì—¬ëŸ¬ ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í¬ë¡¤ë§
    
    Args:
        stocks_data (list): ì£¼ì‹ ì •ë³´ ë¦¬ìŠ¤íŠ¸ 
            [{"code": "004150", "name": "í•œì†”í™€ë”©ìŠ¤"}, {"code": "005930", "name": "ì‚¼ì„±ì „ì"}, ...]
        output_dir (str): ê²°ê³¼ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
        period_type (str): "ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°"
        s3_bucket (str): S3 ë²„í‚·ëª… (ì„ íƒì‚¬í•­)
        save_local (bool): ë¡œì»¬ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        dict: íšŒì‚¬ë³„ í¬ë¡¤ë§ ê²°ê³¼
    """
    print(f"ğŸš€ {len(stocks_data)}ê°œ íšŒì‚¬ì˜ íˆ¬ìë¶„ì„ ë°ì´í„° í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    all_results = {}
    success_count = 0
    failed_companies = []
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ì—¬ íš¨ìœ¨ì„± ì¦ëŒ€)
    crawler = PlaywrightStockCrawler(headless=True, wait_timeout=15000)
    crawler.start_timer()  # íƒ€ì´ë¨¸ ì‹œì‘
    
    try:
        # ë¸Œë¼ìš°ì € ì„¤ì • (í•œ ë²ˆë§Œ)
        await crawler.setup_browser()
        
        for i, stock_info in enumerate(stocks_data):
            company_code = stock_info.get('code', '')
            company_name = stock_info.get('name', f'Company_{company_code}')
            
            print(f"\n{'='*60}")
            print(f"[{i+1}/{len(stocks_data)}] {company_name} ({company_code}) í¬ë¡¤ë§ ì‹œì‘")
            print(f"{'='*60}")
            
            try:
                # URL ìƒì„±
                url = f"https://navercomp.wisereport.co.kr/v2/company/c1040001.aspx?cn=&cmp_cd={company_code}&menuType=block"
                
                # í•´ë‹¹ íšŒì‚¬ í¬ë¡¤ë§ (ë¸Œë¼ìš°ì € ì¬ì‚¬ìš©)
                results = await crawler._crawl_single_company(url, company_code, company_name, period_type)
                
                if results:
                    all_results[company_code] = {
                        'company_name': company_name,
                        'company_code': company_code,
                        'data': results,
                        'status': 'success'
                    }
                    
                    # ê°œë³„ íŒŒì¼ ì €ì¥ì€ í•˜ì§€ ì•ŠìŒ (ìµœì¢… í†µí•© íŒŒì¼ë§Œ ì €ì¥)
                    
                    success_count += 1
                    print(f"âœ… {company_name} í¬ë¡¤ë§ ì„±ê³µ!")
                    
                else:
                    failed_companies.append(f"{company_name}({company_code})")
                    print(f"âŒ {company_name} í¬ë¡¤ë§ ì‹¤íŒ¨ - ë°ì´í„° ì—†ìŒ")
                    
            except Exception as e:
                failed_companies.append(f"{company_name}({company_code})")
                print(f"âŒ {company_name} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                
            # íšŒì‚¬ ê°„ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            if i < len(stocks_data) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´
                print("â³ ë‹¤ìŒ íšŒì‚¬ í¬ë¡¤ë§ì„ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°...")
                await asyncio.sleep(1)
                
    finally:
        await crawler.cleanup()
    
    # Lambda í™˜ê²½ì—ì„œëŠ” ìš”ì•½ íŒŒì¼ ì €ì¥ ìƒëµ (ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì˜¤ë¥˜ ë°©ì§€)
    try:
        # ê°„ë‹¨í•œ ìš”ì•½ ì •ë³´ë§Œ ìƒì„± (DataFrame ì§ë ¬í™” ì—†ì´)
        summary_data = {
            'timestamp': datetime.now(timezone(timedelta(hours=9))).isoformat(),
            'total_companies': len(stocks_data),
            'success_count': success_count,
            'failed_count': len(failed_companies),
            'failed_companies': failed_companies,
            'message': f'{success_count}ê°œ ì„±ê³µ, {len(failed_companies)}ê°œ ì‹¤íŒ¨'
        }

        # Lambda í™˜ê²½ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ìƒì„¸ ìš”ì•½ íŒŒì¼ ì €ì¥
        if not os.environ.get('AWS_LAMBDA_FUNCTION_NAME'):
            print("ğŸ’¾ ë¡œì»¬ í™˜ê²½: ìƒì„¸ ìš”ì•½ íŒŒì¼ ìƒì„± ì¤‘...")

            # DataFrameì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜ (ë¡œì»¬ì—ì„œë§Œ)
            json_compatible_results = {}
            for company_code, company_data in all_results.items():
                json_compatible_results[company_code] = {
                    'company_name': company_data['company_name'],
                    'company_code': company_data['company_code'],
                    'status': company_data.get('status', 'unknown'),
                    'data_count': len(company_data.get('data', {}))
                }

            summary_data['results'] = json_compatible_results

            # ë‚ ì§œ ì ‘ë‘ì‚¬ ì¶”ê°€í•˜ì—¬ JSON ì €ì¥
            date_prefix = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d")
            summary_filename = f"{output_dir}/{date_prefix}_crawling_summary.json"
            with open(summary_filename, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ìš”ì•½ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {summary_filename}")
        else:
            print("â˜ï¸ Lambda í™˜ê²½: ìƒì„¸ ìš”ì•½ íŒŒì¼ ì €ì¥ ìƒëµ")

    except Exception as summary_error:
        print(f"âš ï¸ ìš”ì•½ íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰): {str(summary_error)}")
        summary_data = {
            'timestamp': datetime.now(timezone(timedelta(hours=9))).isoformat(),
            'total_companies': len(stocks_data),
            'success_count': success_count,
            'failed_count': len(failed_companies),
            'message': 'ìš”ì•½ íŒŒì¼ ìƒì„± ì‹¤íŒ¨í•˜ì˜€ìœ¼ë‚˜ í¬ë¡¤ë§ì€ ì™„ë£Œë¨'
        }
    
    # ëª¨ë“  íšŒì‚¬ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ CSV íŒŒì¼ë¡œ í•©ì¹˜ê¸°
    combined_csv_data = []
    for company_code, company_data in all_results.items():
        if company_data.get('status') == 'success' and 'data' in company_data:
            for tab_name, df in company_data['data'].items():
                if isinstance(df, pd.DataFrame) and not df.empty:
                    # íšŒì‚¬ ì •ë³´ì™€ íƒ­ ì •ë³´ ì¶”ê°€
                    df_copy = df.copy()
                    if len(df_copy.columns) > 0:
                        df_copy.insert(0, 'company_code', str(company_code).zfill(6))  # 6ìë¦¬ ë¬¸ìì—´ë¡œ ë³€í™˜
                        df_copy.insert(1, 'company_name', company_data['company_name'])
                    else:
                        df_copy['company_code'] = str(company_code).zfill(6)
                        df_copy['company_name'] = company_data['company_name']
                    
                    # tab_nameì—ì„œ finGubunê³¼ ì‹¤ì œ íƒ­ëª… ë¶„ë¦¬
                    if '_' in tab_name and any(tab_name.endswith(f'_{tab}') for tab in ['ìˆ˜ìµì„±', 'ì„±ì¥ì„±', 'ì•ˆì •ì„±', 'í™œë™ì„±']):
                        # "K-IFRS(ì—°ê²°)_ìˆ˜ìµì„±" í˜•íƒœì—ì„œ ë¶„ë¦¬
                        finGubun_part, actual_tab = tab_name.rsplit('_', 1)
                        
                        # finGubun ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
                        if 'finGubun' not in df_copy.columns:
                            if len(df_copy.columns) >= 2:
                                df_copy.insert(2, 'finGubun', finGubun_part)
                                df_copy.insert(3, 'tab', actual_tab)
                            else:
                                df_copy['finGubun'] = finGubun_part
                                df_copy['tab'] = actual_tab
                        else:
                            # ì´ë¯¸ finGubun ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ tabë§Œ ì¶”ê°€
                            if len(df_copy.columns) >= 3:
                                df_copy.insert(3, 'tab', actual_tab)
                            else:
                                df_copy['tab'] = actual_tab
                    else:
                        # ê¸°ì¡´ í˜•íƒœ (finGubun ì •ë³´ê°€ ì´ë¯¸ ì»¬ëŸ¼ì— ìˆëŠ” ê²½ìš°)
                        # ì•ˆì „í•œ ì¸ë±ìŠ¤ ê³„ì‚°
                        insert_idx = max(0, len(df_copy.columns) - 1) if len(df_copy.columns) > 0 else 0
                        df_copy.insert(insert_idx, 'tab', tab_name)
                    
                    # ì•ˆì „í•œ ì¸ë±ìŠ¤ ê³„ì‚°ìœ¼ë¡œ search_type ì¶”ê°€
                    insert_idx = max(0, len(df_copy.columns) - 1) if len(df_copy.columns) > 0 else 0
                    df_copy.insert(insert_idx, 'search_type', period_type)
                    combined_csv_data.append(df_copy)
    
    # ì „ì²´ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ CSVë¡œ ì €ì¥ í›„ ë³€í™˜
    if combined_csv_data:
        combined_df = pd.concat(combined_csv_data, ignore_index=True)
        
        # ë°ì´í„° ë³€í™˜ (ì»¬ëŸ¼ â†’ í–‰)
        print(f"\nğŸ”„ ì „ì²´ ë°ì´í„° ë³€í™˜ ì¤‘... (ê¸°ê°„: {period_type})")
        
        # ì„ì‹œ í¬ë¡¤ëŸ¬ ê°ì²´ ìƒì„± (ë³€í™˜ ë©”ì†Œë“œ ì‚¬ìš©ì„ ìœ„í•´)
        temp_crawler = PlaywrightStockCrawler()
        transformed_df = temp_crawler.transform_to_row_format(combined_df, period_type)
        
        if not transformed_df.empty:
            # yyyymmë³„ë¡œ ë°ì´í„° ë¶„ë¦¬í•˜ì—¬ ì €ì¥
            temp_crawler = PlaywrightStockCrawler()
            temp_crawler.save_data_by_yyyymm(transformed_df, output_dir, period_type, s3_bucket, save_local)
        else:
            print("âŒ ë°ì´í„° ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("âš ï¸ í†µí•©í•  ë°ì´í„°ê°€ ì—†ì–´ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ì „ì²´ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*60}")
    print(f"ğŸ¢ ì´ íšŒì‚¬ ìˆ˜: {len(stocks_data)}")
    print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_companies)}ê°œ")
    
    if failed_companies:
        print(f"âŒ ì‹¤íŒ¨í•œ íšŒì‚¬ë“¤: {', '.join(failed_companies)}")
    
    print(f"ğŸ’¾ ê²°ê³¼ íŒŒì¼ì´ '{output_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“ yyyymmë³„ ë¶„ë¦¬ëœ íŒŒì¼ë“¤ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“ ìš”ì•½ íŒŒì¼: crawling_summary.json")
    
    # íƒ€ì´ë¨¸ ì¢…ë£Œ
    crawler.end_timer()
    
    return all_results




async def crawl_multiple_stocks_direct(stocks_data, output_dir="./crawl_results", period_type="ì—°ê°„", s3_bucket=None, save_local=True):
    """
    ì¢…ëª© ëª©ë¡ì„ ì§ì ‘ ë°›ì•„ì„œ í¬ë¡¤ë§ (Lambdaì—ì„œ í˜¸ì¶œìš©)

    Args:
        stocks_data (list): ì¢…ëª© ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{"code": "004150", "name": "í•œì†”í™€ë”©ìŠ¤"}, ...]
        output_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        period_type (str): "ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°"
        s3_bucket (str): S3 ë²„í‚·ëª… (ì„ íƒì‚¬í•­)
        save_local (bool): ë¡œì»¬ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    """
    try:
        print(f"[DIRECT] {len(stocks_data)}ê°œ íšŒì‚¬ ì •ë³´ë¡œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"[PERIOD] ê¸°ê°„ íƒ€ì…: {period_type}")

        # ë‹¤ì¤‘ í¬ë¡¤ë§ ì‹¤í–‰
        return await crawl_multiple_stocks(stocks_data, output_dir, period_type, s3_bucket, save_local)

    except Exception as e:
        import traceback
        print(f"[ERROR] ì§ì ‘ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"[ERROR] ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        print(traceback.format_exc())
        raise


def run_multiple_crawler(stocks_json_file, output_dir="./crawl_results", period_type="ì—°ê°„", s3_bucket=None, save_local=True):
    """
    JSON íŒŒì¼ì—ì„œ ì£¼ì‹ ëª©ë¡ì„ ì½ì–´ ì—¬ëŸ¬ íšŒì‚¬ í¬ë¡¤ë§

    Args:
        stocks_json_file (str): ì£¼ì‹ ëª©ë¡ JSON íŒŒì¼ ê²½ë¡œ
        output_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        period_type (str): "ì—°ê°„" ë˜ëŠ” "ë¶„ê¸°"
        s3_bucket (str): S3 ë²„í‚·ëª… (ì„ íƒì‚¬í•­)
        save_local (bool): ë¡œì»¬ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    """
    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(stocks_json_file, 'r', encoding='utf-8') as f:
            stocks_data = json.load(f)

        print(f"[FILE] {stocks_json_file}ì—ì„œ {len(stocks_data)}ê°œ íšŒì‚¬ ì •ë³´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        print(f"[PERIOD] ê¸°ê°„ íƒ€ì…: {period_type}")

        # Windows ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
        if os.name == 'nt':
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

        # ë‹¤ì¤‘ í¬ë¡¤ë§ ì‹¤í–‰
        asyncio.run(crawl_multiple_stocks(stocks_data, output_dir, period_type, s3_bucket, save_local))

    except FileNotFoundError:
        print(f"[ERROR] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {stocks_json_file}")
        print("[INFO] ì˜ˆì‹œ JSON íŒŒì¼ í˜•ì‹:")
        print("""[
  {"code": "004150", "name": "í•œì†”í™€ë”©ìŠ¤"},
  {"code": "005930", "name": "ì‚¼ì„±ì „ì"},
  {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤"}
]""")
    except json.JSONDecodeError:
        print(f"[ERROR] JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {stocks_json_file}")
    except Exception as e:
        import traceback
        print(f"[ERROR] ë‹¤ì¤‘ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"[ERROR] ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        print(traceback.format_exc())


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        # ëª…ë ¹ì¤„ ì¸ìˆ˜ê°€ ìˆìœ¼ë©´ ë‹¤ì¤‘ í¬ë¡¤ë§
        stocks_file = sys.argv[1]
        output_dir = sys.argv[2] if len(sys.argv) > 2 else "./crawl_results"
        period_type = sys.argv[3] if len(sys.argv) > 3 else "ì—°ê°„"
        run_multiple_crawler(stocks_file, output_dir, period_type)
    else:
        print("[USAGE] ì‚¬ìš©ë²•: python naver_stock_invest_index_crawler.py <stocks.json> [output_dir] [period_type]")
        print("        ì˜ˆì‹œ: python naver_stock_invest_index_crawler.py stocks.json ./results daily/quarter/annual")
