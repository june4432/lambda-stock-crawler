"""
ì£¼ì‹ í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ - AWS Lambdaìš© ë©”ì¸ ì§„ì…ì 
íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í¬ë¡¤ëŸ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” íŒ©í† ë¦¬ ë©”ì„œë“œ
"""

import json
import os
import asyncio
from datetime import datetime, timezone, timedelta
import boto3
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ)
if os.path.exists('.env'):
    load_dotenv()


def factory_lambda_handler(event, context):
    """
    ì£¼ì‹ í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ Lambda í•¸ë“¤ëŸ¬
    
    Args:
        event (dict): Lambda ì´ë²¤íŠ¸ ë°ì´í„°
            - crawler_type: 'daily', 'quarter', 'annual'
            - s3_bucket: S3 ë²„í‚·ëª… (ì„ íƒì‚¬í•­)
            - delay_between_stocks: ì¢…ëª© ê°„ ëŒ€ê¸°ì‹œê°„ (ì„ íƒì‚¬í•­)
        context: Lambda ì»¨í…ìŠ¤íŠ¸
        
    Returns:
        dict: HTTP ì‘ë‹µ
    """
    try:
        # í™˜ê²½ë³€ìˆ˜ ìš°ì„ ìˆœìœ„ë¡œ ì„¤ì •ê°’ ì½ê¸° (í™˜ê²½ë³€ìˆ˜ > ì´ë²¤íŠ¸ íŒŒë¼ë¯¸í„° > ê¸°ë³¸ê°’)
        crawler_type = os.environ.get('CRAWLER_TYPE') or event.get('crawler_type') or 'daily'
        s3_bucket = os.environ.get('S3_BUCKET') or event.get('s3_bucket') or 'test-stock-info-bucket'
        delay_between_stocks = int(os.environ.get('DELAY_BETWEEN_STOCKS') or event.get('delay_between_stocks') or '2')
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ê°’ ì¶œë ¥
        print(f"ğŸ” í™˜ê²½ë³€ìˆ˜ ë””ë²„ê¹…:")
        print(f"   CRAWLER_TYPE: {os.environ.get('CRAWLER_TYPE', 'None')}")
        print(f"   S3_BUCKET: {os.environ.get('S3_BUCKET', 'None')}")
        print(f"   DELAY_BETWEEN_STOCKS: {os.environ.get('DELAY_BETWEEN_STOCKS', 'None')}")
        print(f"ğŸ” ì´ë²¤íŠ¸ íŒŒë¼ë¯¸í„°:")
        print(f"   crawler_type: {event.get('crawler_type', 'None')}")
        print(f"   s3_bucket: {event.get('s3_bucket', 'None')}")
        print(f"   delay_between_stocks: {event.get('delay_between_stocks', 'None')}")
        print(f"ğŸš€ ì£¼ì‹ í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ ì‹œì‘ - íƒ€ì…: {crawler_type}, ë²„í‚·: {s3_bucket}, ë”œë ˆì´: {delay_between_stocks}ì´ˆ")
        
        # ì´ë²¤íŠ¸ì— í™˜ê²½ë³€ìˆ˜ ê°’ë“¤ ì¶”ê°€
        event_with_env = event.copy()
        event_with_env['s3_bucket'] = s3_bucket
        event_with_env['delay_between_stocks'] = delay_between_stocks
        
        # íƒ€ì…ì— ë”°ë¼ ë¶„ê¸°
        if crawler_type == 'daily':
            return handle_daily_crawler(event_with_env, context)
        elif crawler_type == 'quarter':
            return handle_quarter_crawler(event_with_env, context)
        elif crawler_type == 'annual':
            return handle_annual_crawler(event_with_env, context)
        else:
            return {
                'statusCode': 400,
                'headers': {
                    'Content-Type': 'application/json; charset=utf-8'
                },
                'body': json.dumps({
                    'success': False,
                    'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” í¬ë¡¤ëŸ¬ íƒ€ì…: {crawler_type}',
                    'supported_types': ['daily', 'quarter', 'annual']
                }, ensure_ascii=False, indent=2)
            }
            
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8'
            },
            'body': json.dumps({
                'success': False,
                'error': f'íŒ©í† ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, ensure_ascii=False, indent=2)
        }


def handle_daily_crawler(event, context):
    """
    ì¼ê°„ íˆ¬ìì •ë³´ í¬ë¡¤ëŸ¬ ì‹¤í–‰ (PER/EPS)
    """
    print("ğŸ“Š ì¼ê°„ íˆ¬ìì •ë³´(PER/EPS) í¬ë¡¤ëŸ¬ ì‹¤í–‰")
    
    # ê¸°ì¡´ naver_stock_invest_info_crawler ëª¨ë“ˆ import
    from naver_stock_invest_info_crawler import lambda_handler
    
    # í•´ë‹¹ í•¸ë“¤ëŸ¬ ì‹¤í–‰
    return lambda_handler(event, context)


def handle_quarter_crawler(event, context):
    """
    ë¶„ê¸°ë³„ ì¬ë¬´ì •ë³´ í¬ë¡¤ëŸ¬ ì‹¤í–‰
    """
    print("ğŸ“ˆ ë¶„ê¸°ë³„ ì¬ë¬´ì •ë³´ í¬ë¡¤ëŸ¬ ì‹¤í–‰")

    try:
        # naver_stock_invest_index_crawler ëª¨ë“ˆ import
        from naver_stock_invest_index_crawler import crawl_multiple_stocks_direct

        # ëŒë‹¤ í‘ì…˜ì—ì„œ ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        try:
            import urllib.request
            import urllib.error

            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëŒë‹¤ URL ê°€ì ¸ì˜¤ê¸°
            lambda_url = os.environ.get('STOCK_LAMBDA_URL', 'https://rbtvqk5rybgcl63umd5skjnc4i0tqjpl.lambda-url.ap-northeast-2.on.aws/')
            print(f"ğŸ“‹ ëŒë‹¤ í‘ì…˜ì—ì„œ ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°: {lambda_url}")

            with urllib.request.urlopen(lambda_url, timeout=30) as response:
                response_data = response.read().decode('utf-8')

            print(f"ğŸ” ëŒë‹¤ ì‘ë‹µ ë°ì´í„°: {response_data[:500]}...")

            api_response = json.loads(response_data)
            print(f"ğŸ” API ì‘ë‹µ êµ¬ì¡°: {type(api_response)}")

            # API ì‘ë‹µ ê²€ì¦
            if not api_response.get('success'):
                error_msg = api_response.get('error', 'Unknown error')
                raise Exception(f"ëŒë‹¤ API í˜¸ì¶œ ì‹¤íŒ¨: {error_msg}")

            # ë°ì´í„° ì¶”ì¶œ
            raw_stocks = api_response.get('data', [])
            print(f"ğŸ“‹ ëŒë‹¤ APIì—ì„œ {len(raw_stocks)}ê°œ íšŒì‚¬ ë°ì´í„° ìˆ˜ì‹ ")

            # stock_codeê°€ nullì´ ì•„ë‹Œ ê°’ë§Œ í•„í„°ë§í•˜ê³  ë³€í™˜
            stocks = []
            for stock in raw_stocks:
                stock_code = stock.get('stock_code')
                stock_nm = stock.get('stock_nm')

                # stock_codeê°€ ìˆëŠ” ê²½ìš°ë§Œ (ì´ í”„ë¡œì íŠ¸ìš©)
                if stock_code and stock_nm:
                    stocks.append({
                        'code': stock_code,
                        'name': stock_nm
                    })

            print(f"ğŸ“‹ ëŒë‹¤ í‘ì…˜ì—ì„œ {len(stocks)}ê°œ ìœ íš¨í•œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            return {
                'statusCode': 500,
                'headers': {
                    'Content-Type': 'application/json; charset=utf-8'
                },
                'body': json.dumps({
                    'success': False,
                    'error': f'ëŒë‹¤ í‘ì…˜ì—ì„œ ì¢…ëª© ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}'
                }, ensure_ascii=False, indent=2)
            }
        
        # ë¶„ê¸°ë³„ í¬ë¡¤ë§ ì‹¤í–‰
        print("ğŸš€ ë¶„ê¸°ë³„ ì¬ë¬´ì •ë³´ í¬ë¡¤ë§ ì‹œì‘")

        # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = "/tmp/crawl_results"
        os.makedirs(output_dir, exist_ok=True)

        # s3_bucket ì„¤ì •
        s3_bucket = os.environ.get('S3_BUCKET') or event.get('s3_bucket') or 'test-stock-info-bucket'

        # crawl_multiple_stocks_direct ì‹¤í–‰ (ë¶„ê¸°) - ì¢…ëª© ëª©ë¡ì„ ì§ì ‘ ì „ë‹¬
        import asyncio
        if os.name == 'nt':
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

        crawl_result = asyncio.run(crawl_multiple_stocks_direct(stocks, output_dir, "ë¶„ê¸°", s3_bucket))

        # í¬ë¡¤ë§ ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ìš”ì•½
        if crawl_result:
            summary_result = {
                "success": True,
                "total_companies": len(stocks),
                "message": f"{len(stocks)}ê°œ íšŒì‚¬ì˜ ë¶„ê¸°ë³„ ì¬ë¬´ì •ë³´ í¬ë¡¤ë§ ì™„ë£Œ",
                "output_directory": output_dir,
                "s3_bucket": s3_bucket
            }
        else:
            summary_result = {
                "success": False,
                "message": "í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            }

        # S3 ì—…ë¡œë“œ ê²°ê³¼
        s3_upload_result = {
            "success": True,
            "message": "S3 ì—…ë¡œë“œëŠ” í¬ë¡¤ë§ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨"
        }

        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8'
            },
            'body': json.dumps({
                'success': True,
                'crawler_type': 'quarter',
                'crawl_result': summary_result,
                's3_upload': s3_upload_result,
                'crawl_time': datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")
            }, ensure_ascii=False, indent=2)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8'
            },
            'body': json.dumps({
                'success': False,
                'error': f'ë¶„ê¸°ë³„ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, ensure_ascii=False, indent=2)
        }


def handle_annual_crawler(event, context):
    """
    ì—°ê°„ ì¬ë¬´ì •ë³´ í¬ë¡¤ëŸ¬ ì‹¤í–‰
    """
    print("ğŸ“Š ì—°ê°„ ì¬ë¬´ì •ë³´ í¬ë¡¤ëŸ¬ ì‹¤í–‰")

    try:
        # naver_stock_invest_index_crawler ëª¨ë“ˆ import
        from naver_stock_invest_index_crawler import crawl_multiple_stocks_direct

        # ëŒë‹¤ í‘ì…˜ì—ì„œ ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        try:
            import urllib.request
            import urllib.error

            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ëŒë‹¤ URL ê°€ì ¸ì˜¤ê¸°
            lambda_url = os.environ.get('STOCK_LAMBDA_URL', 'https://rbtvqk5rybgcl63umd5skjnc4i0tqjpl.lambda-url.ap-northeast-2.on.aws/')
            print(f"ğŸ“‹ ëŒë‹¤ í‘ì…˜ì—ì„œ ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°: {lambda_url}")

            with urllib.request.urlopen(lambda_url, timeout=30) as response:
                response_data = response.read().decode('utf-8')

            print(f"ğŸ” ëŒë‹¤ ì‘ë‹µ ë°ì´í„°: {response_data[:500]}...")

            api_response = json.loads(response_data)
            print(f"ğŸ” API ì‘ë‹µ êµ¬ì¡°: {type(api_response)}")

            # API ì‘ë‹µ ê²€ì¦
            if not api_response.get('success'):
                error_msg = api_response.get('error', 'Unknown error')
                raise Exception(f"ëŒë‹¤ API í˜¸ì¶œ ì‹¤íŒ¨: {error_msg}")

            # ë°ì´í„° ì¶”ì¶œ
            raw_stocks = api_response.get('data', [])
            print(f"ğŸ“‹ ëŒë‹¤ APIì—ì„œ {len(raw_stocks)}ê°œ íšŒì‚¬ ë°ì´í„° ìˆ˜ì‹ ")

            # stock_codeê°€ nullì´ ì•„ë‹Œ ê°’ë§Œ í•„í„°ë§í•˜ê³  ë³€í™˜
            stocks = []
            for stock in raw_stocks:
                stock_code = stock.get('stock_code')
                stock_nm = stock.get('stock_nm')

                # stock_codeê°€ ìˆëŠ” ê²½ìš°ë§Œ (ì´ í”„ë¡œì íŠ¸ìš©)
                if stock_code and stock_nm:
                    stocks.append({
                        'code': stock_code,
                        'name': stock_nm
                    })

            print(f"ğŸ“‹ ëŒë‹¤ í‘ì…˜ì—ì„œ {len(stocks)}ê°œ ìœ íš¨í•œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            return {
                'statusCode': 500,
                'headers': {
                    'Content-Type': 'application/json; charset=utf-8'
                },
                'body': json.dumps({
                    'success': False,
                    'error': f'ëŒë‹¤ í‘ì…˜ì—ì„œ ì¢…ëª© ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {str(e)}'
                }, ensure_ascii=False, indent=2)
            }
        
        # ì—°ê°„ í¬ë¡¤ë§ ì‹¤í–‰
        print("ğŸš€ ì—°ê°„ ì¬ë¬´ì •ë³´ í¬ë¡¤ë§ ì‹œì‘")

        # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir = "/tmp/crawl_results"
        os.makedirs(output_dir, exist_ok=True)

        # s3_bucket ì„¤ì •
        s3_bucket = os.environ.get('S3_BUCKET') or event.get('s3_bucket') or 'test-stock-info-bucket'

        # crawl_multiple_stocks_direct ì‹¤í–‰ (ì—°ê°„) - ì¢…ëª© ëª©ë¡ì„ ì§ì ‘ ì „ë‹¬
        import asyncio
        if os.name == 'nt':
            asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

        crawl_result = asyncio.run(crawl_multiple_stocks_direct(stocks, output_dir, "ì—°ê°„", s3_bucket))

        # í¬ë¡¤ë§ ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ìš”ì•½
        if crawl_result:
            summary_result = {
                "success": True,
                "total_companies": len(stocks),
                "message": f"{len(stocks)}ê°œ íšŒì‚¬ì˜ ì—°ê°„ ì¬ë¬´ì •ë³´ í¬ë¡¤ë§ ì™„ë£Œ",
                "output_directory": output_dir,
                "s3_bucket": s3_bucket
            }
        else:
            summary_result = {
                "success": False,
                "message": "í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
            }

        # S3 ì—…ë¡œë“œ ê²°ê³¼
        s3_upload_result = {
            "success": True,
            "message": "S3 ì—…ë¡œë“œëŠ” í¬ë¡¤ë§ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨"
        }

        return {
            'statusCode': 200,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8'
            },
            'body': json.dumps({
                'success': True,
                'crawler_type': 'annual',
                'crawl_result': summary_result,
                's3_upload': s3_upload_result,
                'crawl_time': datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S")
            }, ensure_ascii=False, indent=2)
        }
        
    except Exception as e:
        return {
            'statusCode': 500,
            'headers': {
                'Content-Type': 'application/json; charset=utf-8'
            },
            'body': json.dumps({
                'success': False,
                'error': f'ì—°ê°„ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, ensure_ascii=False, indent=2)
        }


if __name__ == "__main__":
    print("ğŸ­ ì£¼ì‹ í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ - ë¡œì»¬ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸ (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    test_events = [
        # {
        #     'crawler_type': os.environ.get('CRAWLER_TYPE', 'daily'),
        #     's3_bucket': os.environ.get('S3_BUCKET', 'test-stock-info-bucket'),
        #     'delay_between_stocks': int(os.environ.get('DELAY_BETWEEN_STOCKS', '2'))
        # },
        {
           'crawler_type': 'quarter',
           's3_bucket': os.environ.get('S3_BUCKET', 'test-stock-info-bucket'),
           'delay_between_stocks': int(os.environ.get('DELAY_BETWEEN_STOCKS', '2'))
        }
        # ,
        # {
        #    'crawler_type': 'annual',
        #    's3_bucket': os.environ.get('S3_BUCKET', 'test-stock-info-bucket'),
        #    'delay_between_stocks': int(os.environ.get('DELAY_BETWEEN_STOCKS', '2'))
        # }
    ]
    
    for test_event in test_events:
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸: {test_event['crawler_type']}")
        result = factory_lambda_handler(test_event, None)
        print(f"ê²°ê³¼ ìƒíƒœì½”ë“œ: {result['statusCode']}")
        
        if result['statusCode'] == 200:
            body = json.loads(result['body'])
            print(f"âœ… ì„±ê³µ: {body.get('success', False)}")
        else:
            print(f"âŒ ì‹¤íŒ¨: {result['statusCode']}")
